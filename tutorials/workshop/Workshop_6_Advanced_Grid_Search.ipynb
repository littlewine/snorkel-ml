{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img align=\"left\" src=\"imgs/logo.jpg\" width=\"50px\" style=\"margin-right:10px\">\n",
    "# Snorkel Workshop: Extracting Spouse Relations <br> from the News\n",
    "## Advanced Part 6:  Hyperparameter Tuning via Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database backend and initalize a Snorkel session\n",
    "from lib.init import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We repeat our definition of the `Spouse` `Candidate` subclass, and load the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "Spouse = candidate_subclass('Spouse', ['person1', 'person2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# I. Training a `SparseLogisticRegression` Discriminative Model\n",
    "We use the training marginals to train a discriminative model that classifies each `Candidate` as a true or false mention. We'll use a random hyperparameter search, evaluated on the development set labels, to find the best hyperparameters for our model. To run a hyperparameter search, we need labels for a development set. If they aren't already available, we can manually create labels using the Viewer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Feature Extraction\n",
    "Instead of using a deep learning approach to start, let's look at a standard sparse logistic regression model. First, we need to extract out features. This can take a while, but we only have to do it once!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import FeatureAnnotator\n",
    "featurizer = FeatureAnnotator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "F_train = featurizer.load_matrix(session, split=0)\n",
    "F_dev = featurizer.load_matrix(session, split=1)\n",
    "F_test = featurizer.load_matrix(session, split=2)\n",
    "\n",
    "if F_train.size == 0:    \n",
    "    %time F_train = featurizer.apply(split=0, parallelism=1)\n",
    "if F_dev.size == 0:     \n",
    "    %time F_dev  = featurizer.apply_existing(split=1, parallelism=1)\n",
    "if F_test.size == 0:\n",
    "    %time F_test = featurizer.apply_existing(split=2, parallelism=1)\n",
    "\n",
    "print F_train.shape\n",
    "print F_dev.shape\n",
    "print F_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "\n",
    "First, reload the training marginals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our development data for tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The following code performs model selection by tuning our learning algorithm's hyperparamters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import RandomSearch\n",
    "from snorkel.learning import SparseLogisticRegression\n",
    "\n",
    "seed = 1234\n",
    "num_model_search = 10\n",
    "\n",
    "# search over this parameter grid\n",
    "param_grid = {}\n",
    "param_grid['batch_size'] = [64, 128]\n",
    "param_grid['lr']         = [1e-4, 1e-3, 1e-2]\n",
    "param_grid['l1_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "param_grid['l2_penalty'] = [1e-6, 1e-4, 1e-2]\n",
    "param_grid['rebalance']  = [0.0, 0.5]\n",
    "\n",
    "model_class_params = {\n",
    "    'seed': seed,\n",
    "    'n_threads':num_procs\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'n_epochs': 2000,\n",
    "    'print_freq': 1,\n",
    "    'dev_ckpt_delay': 0.5,\n",
    "    'X_dev': F_dev,\n",
    "    'Y_dev': L_gold_dev\n",
    "}\n",
    "\n",
    "searcher = RandomSearch(SparseLogisticRegression, param_grid, F_train, train_marginals,\n",
    "                        n=num_model_search, seed=seed,\n",
    "                        model_class_params=model_class_params,\n",
    "                        model_hyperparams=model_hyperparams)\n",
    "\n",
    "print \"Discriminitive Model Parameter Space (seed={}):\".format(seed)\n",
    "for i, params in enumerate(searcher.search_space()):\n",
    "    print i, params\n",
    "\n",
    "disc_model, run_stats = searcher.fit(X_valid=F_dev, Y_valid=L_gold_dev, n_threads=1)\n",
    "print run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Examining Features\n",
    "Extracting features allows us to inspect and interperet our learned weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from lib.scoring import *\n",
    "print_top_k_features(session, disc_model, F_train, top_k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Evaluate on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_gold_labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "_, _, _, _ = disc_model.score(session, F_test, L_gold_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
