{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Searching for Model Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In this notebook, we'll demonstrate how to automatically select hyperparameters based on a labeled development set. Also check out the [CDR tutorial](https://github.com/HazyResearch/snorkel/tree/master/tutorials/cdr) for an example use case of grid search!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generating Some Data\n",
    "\n",
    "We'll start by generating a synthetic label matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModelWeights\n",
    "from snorkel.learning.structure import generate_label_matrix\n",
    "\n",
    "weights = GenerativeModelWeights(10)\n",
    "for i in range(10):\n",
    "    weights.lf_accuracy[i] = 2.5\n",
    "weights.dep_similar[0, 1] = 0.25\n",
    "weights.dep_similar[2, 3] = 0.25\n",
    "\n",
    "L_gold_train, L_train = generate_label_matrix(weights, 10000)\n",
    "L_gold_dev, L_dev = generate_label_matrix(weights, 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generative Model Hyperparameters\n",
    "\n",
    "Below we use `RandomSearch` to search over a random set (with `n=5` below) of hyperparameter configurations, validating on the development set and saving the best model. Note we can also use the `GridSearch` class to search over _all_ combinations of hyperparameters. We start by defining the model, then the parameter ranges to search over, then the searcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import GenerativeModel\n",
    "from snorkel.learning import RandomSearch\n",
    "\n",
    "param_ranges = {\n",
    "    'step_size' : [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'decay' : [1.0, 0.95, 0.9],\n",
    "    'epochs' : [20, 50, 100]\n",
    "}\n",
    "\n",
    "searcher = RandomSearch(GenerativeModel, param_ranges, L_train, n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we fit to the dev set--i.e. we execute the search, scoring and selecting the best configuration according to the dev set score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "[1] Testing epochs = 100, step_size = 1.00e-04, decay = 9.50e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model saved as <GenerativeModel_0>.\n",
      "============================================================\n",
      "[2] Testing epochs = 50, step_size = 1.00e-03, decay = 9.00e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[3] Testing epochs = 100, step_size = 1.00e-05, decay = 9.50e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[4] Testing epochs = 100, step_size = 1.00e-04, decay = 1.00e+00\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "============================================================\n",
      "[5] Testing epochs = 20, step_size = 1.00e-05, decay = 9.50e-01\n",
      "============================================================\n",
      "Inferred cardinality: 2\n",
      "[GenerativeModel] F-1 Score: 1.0\n",
      "[GenerativeModel] Model <GenerativeModel_0> loaded.\n",
      "CPU times: user 1min 57s, sys: 589 ms, total: 1min 58s\n",
      "Wall time: 1min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gen_model, run_stats = searcher.fit(L_dev, L_gold_dev)\n",
    "run_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the best learned model.\n",
    "\n",
    "**Note that this is just a toy example- the above search may not be that interesting (i.e. all models may get perfect scores). But in practice, hyperparameter tuning is extremely important, especially for the end discriminative model (see below).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note that in other tutorials, this is often named `train_marginals`!\n",
    "Y_train = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallel Grid Search: `GridSearchMP`\n",
    "\n",
    "You can run `GridSearch` (and any subclasses like `RandomSearch`) in parallel just by specifying the `n_threads` keyword argument in the `fit` method!\n",
    "\n",
    "**Note: When running TensorFlow models in parallel, it is often necessary to throttle the number of threads that each individual model / process tries to use.  You can set that by settting `n_threads` in the initialization of the `GridSearch` object (here, this kwarg is for the discriminative model class).**\n",
    "\n",
    "*Note #2: There is currently an unknown issue with running parallel grid search in a notebook where other models have already been run (see [Issue #707](https://github.com/HazyResearch/snorkel/issues/707)), so recommended usage for now is to run in a separate notebook / from the command line.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminative Model Hyperparameters\n",
    "\n",
    "Hyperparameter search can also be used in the same way for the discriminative model, and in fact this is currently the most popular use of it! Below is example code:\n",
    "\n",
    "```\n",
    "from snorkel.learning import reRNN\n",
    "\n",
    "param_ranges = {\n",
    "    'lr' : [1e-2, 1e-3, 1e-4, 1e-5, 1e-6],\n",
    "    'dropout' : [0.0, 0.5]\n",
    "}\n",
    "\n",
    "model_hyperparams = {\n",
    "    'n_epochs' : 50,\n",
    "    'rebalance' : 0.5,\n",
    "    'print_freq' : 25\n",
    "}\n",
    "\n",
    "# We now add a session and probabilistic labels, as well as pass in the candidates\n",
    "# instead of the label matrix\n",
    "searcher = RandomSearch(reRNN, param_ranges, train_candidates, Y_train=Y_train, n=5,\n",
    "    model_hyperparams=model_hyperparams)\n",
    "\n",
    "# We now pass in the development candidates and the gold development labels\n",
    "lstm, run_stats = searcher.fit(dev_candidates, L_gold_dev)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
