{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical-Disease Relation (CDR) Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial will show off some of the more advanced features of Snorkel, so we'll assume you've followed the Intro tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task Description\n",
    "\n",
    "The CDR task is comprised of three sets of 500 documents each, called training, development, and test. A document consists of the title and abstract of an article from [PubMed](https://www.ncbi.nlm.nih.gov/pubmed/), an archive of biomedical and life sciences journal literature. The documents have been hand-annotated with\n",
    "* Mentions of chemicals and diseases along with their [MESH](https://meshb.nlm.nih.gov/#/fieldSearch) IDs, canonical IDs for medical entities. For example, mentions of \"warfarin\" in two different documents will have the same ID.\n",
    "* Chemical-disease relations at the document-level. That is, if some piece of text in the document implies that a chemical with MESH ID `X` induces a disease with MESH ID `Y`, the document will be annotated with `Relation(X, Y)`.\n",
    "\n",
    "The goal is to extract the document-level relations on the test set (without accessing the entity or relation annotations). For this tutorial, we make the following assumptions and alterations to the task:\n",
    "* We discard all of the entity mention annotations and assume we have access to a state-of-the-art entity tagger (see Part I) to identify chemical and disease mentions, and link them to their canonical IDs.\n",
    "* We shuffle the training and development sets a bit, producing a new training set with 900 documents and a new development set with 100 documents. We discard the training set relation annotations, but keep the development set to evaluate our labeling functions and extraction model.\n",
    "* We evaluate the task at the mention-level, rather than the document-level. We will convert the document-level relation annotations to mention-level by simply saying that a mention pair `(X, Y)` in document `D` if `Relation(X, Y)` was hand-annotated at the document-level for `D`.\n",
    "\n",
    "In effect, the only inputs to this application are the plain text of the documents, a pre-trained entity tagger, and a small development set of annotated documents. This is representative of many information extraction tasks, and Snorkel is the perfect tool to bootstrap the extraction process with weak supervision. Let's get going."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Initial Prep\n",
    "\n",
    "In your shell, download the raw data by running:\n",
    "```bash\n",
    "cd tutorials/cdr\n",
    "./download_data.sh\n",
    "```\n",
    "\n",
    "Note that if you've previously run this tutorial (using SQLite), you can delete the old database by running (in the same directory as above):\n",
    "```bash\n",
    "rm snorkel.db\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Corpus Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring a `DocPreprocessor`\n",
    "\n",
    "We'll start by defining a `DocPreprocessor` object to read in Pubmed abstracts from [Pubtator]([Pubtator](http://www.ncbi.nlm.nih.gov/CBBresearch/Lu/Demo/PubTator/index.cgi). There some extra annotation information in the file, while we'll skip for now. We'll use the `XMLMultiDocPreprocessor` class, which allows us to use [XPath queries](https://en.wikipedia.org/wiki/XPath) to specify the relevant sections of the XML format.\n",
    "\n",
    "Note that we are newline-concatenating text from the title and abstract together for simplicity, but if we wanted to, we could easily extend the `DocPreprocessor` classes to preserve information about document structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snorkel.parser import XMLMultiDocPreprocessor\n",
    "\n",
    "# The following line is for testing only. Feel free to ignore it.\n",
    "file_path = 'data/CDR.BioC.small.xml' if 'CI' in os.environ else 'data/CDR.BioC.xml'\n",
    "\n",
    "doc_preprocessor = XMLMultiDocPreprocessor(\n",
    "    path=file_path,\n",
    "    doc='.//document',\n",
    "    text='.//passage/text/text()',\n",
    "    id='.//id/text()'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a `CorpusParser`\n",
    "\n",
    "Similar to the Intro tutorial, we'll now construct a `CorpusParser` using the preprocessor we just defined. However, this one has an extra ingredient: an entity tagger. [TaggerOne](https://www.ncbi.nlm.nih.gov/pubmed/27283952) is a popular entity tagger for PubMed, so we went ahead and preprocessed its tags on the CDR corpus for you. The function `TaggerOneTagger.tag` (in `utils.py`) tags sentences with mentions of chemicals and diseases. We'll use these tags to extract candidates in Part II. The tags are stored in `Sentence.entity_cids` and `Sentence.entity_types`, which are analog to `Sentence.words`.\n",
    "\n",
    "Recall that in the wild, we wouldn't have the manual labels included with the CDR data, and we'd have to use an automated tagger (like TaggerOne) to tag entity mentions. That's what we're doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser\n",
    "from utils import TaggerOneTagger\n",
    "\n",
    "tagger_one = TaggerOneTagger()\n",
    "corpus_parser = CorpusParser(fn=tagger_one.tag)\n",
    "corpus_parser.apply(list(doc_preprocessor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Documents:', 1500)\n",
      "('Sentences:', 14001)\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import Document, Sentence\n",
    "\n",
    "print(\"Documents:\", session.query(Document).count())\n",
    "print(\"Sentences:\", session.query(Sentence).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('Chemical|D003000', 49, 58),\n",
       " ('Chemical|D003000', 181, 190),\n",
       " ('Chemical|D003000', 487, 496),\n",
       " ('Chemical|D003000', 637, 646),\n",
       " ('Chemical|D003000', 878, 887),\n",
       " ('Chemical|D003000', 1026, 1035),\n",
       " ('Chemical|D008750', 306, 322),\n",
       " ('Chemical|D008750', 1039, 1055),\n",
       " ('Chemical|D009270', 0, 8),\n",
       " ('Chemical|D009270', 354, 362),\n",
       " ('Chemical|D009270', 364, 372),\n",
       " ('Chemical|D009270', 563, 576),\n",
       " ('Chemical|D009270', 589, 597),\n",
       " ('Chemical|D009270', 865, 873),\n",
       " ('Disease|D006973', 93, 105),\n",
       " ('Disease|D006973', 469, 481),\n",
       " ('Disease|D006973', 750, 762),\n",
       " ('Disease|D007022', 274, 285)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger_one.tag_dict.get('227508', {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = session.query(Sentence)\n",
    "# obj.first().entity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(Document 227508,1,In unanesthetized, spontaneously hypertensive rats the decrease in blood pressure and heart rate produced by intravenous clonidine, 5 to 20 micrograms/kg, was inhibited or reversed by nalozone, 0.2 to 2 mg/kg.)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj.all()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence(Document 227508,2,The hypotensive effect of 100 mg/kg alpha-methyldopa was also partially reversed by naloxone.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1 = obj.all()[0]\n",
    "sent1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " 'D006973',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " 'D003000',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.entity_cids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " 'Disease',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " 'Chemical',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.entity_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " 'Disease',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " 'Chemical',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O',\n",
       " u'O']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent1.entity_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Candidate Extraction\n",
    "\n",
    "With the TaggerOne entity tags, candidate extraction is pretty easy! We split into some preset training, development, and test sets. Then we'll use PretaggedCandidateExtractor to extract candidates using the TaggerOne entity tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves.cPickle import load\n",
    "\n",
    "with open('data/doc_ids.pkl', 'rb') as f:\n",
    "    train_ids, dev_ids, test_ids = load(f)\n",
    "train_ids, dev_ids, test_ids = set(train_ids), set(dev_ids), set(test_ids)\n",
    "\n",
    "train_sents, dev_sents, test_sents = set(), set(), set()\n",
    "docs = session.query(Document).order_by(Document.name).all()\n",
    "for i, doc in enumerate(docs):\n",
    "    for s in doc.sentences:\n",
    "        if doc.name in train_ids:\n",
    "            train_sents.add(s)\n",
    "        elif doc.name in dev_ids:\n",
    "            dev_sents.add(s)\n",
    "        elif doc.name in test_ids:\n",
    "            test_sents.add(s)\n",
    "        else:\n",
    "            raise Exception('ID <{0}> not found in any id set'.format(doc.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.candidates import PretaggedCandidateExtractor\n",
    "\n",
    "candidate_extractor = PretaggedCandidateExtractor(ChemicalDisease, ['Chemical', 'Disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should get 8268 candidates in the training set, 888 candidates in the development set, and 4620 candidates in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 8272)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 888)\n",
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "('Number of candidates:', 4620)\n"
     ]
    }
   ],
   "source": [
    "for k, sents in enumerate([train_sents, dev_sents, test_sents]):\n",
    "    candidate_extractor.apply(sents, split=k)\n",
    "    print(\"Number of candidates:\", session.query(ChemicalDisease).filter(ChemicalDisease.split == k).count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate Recall\n",
    "We will briefly discuss the issue of candidate recall. The end-recall of the extraction is effectively upper-bounded by our candidate set: any chemical-disease pair that is present in a document but not identified as a candidate cannot be extracted by our end extraction model. Below are some example reasons for missing a candidate<sup>1</sup>.\n",
    "* The tagger is imperfect, and may miss a chemical or disease mention.\n",
    "* The tagger is imperfect, and may attach an incorrect entity ID to a correctly identified chemical or disease mention. For example, \"stomach pain\" might get attached to the entity ID for \"digestive track infection\" rather than \"stomach illness\".\n",
    "* A relation occurs across multiple sentences. For example, \"**Artery calcification** is more prominient in older populations. It can be induced by **warfarin**.\"\n",
    "\n",
    "If we just look at the set of extractions at the end of this tutorial, we won't be able to account for some false negatives that we missed at the candidate extraction stage. For simplicity, we ignore candidate recall in this tutorial and evaluate our extraction model just on the set of extractions made by the end model. However, when you're developing information extraction applications in the future, it's important to keep candidate recall in mind.\n",
    "\n",
    "<sup>1</sup>Note that these specific issues can be combatted with advanced techniques like noun-phrase chunking to expand the entity mention set, or coreference parsing for cross-sentence candidates. We don't employ these here in order to focus on weak supervision."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:python27]",
   "language": "python",
   "name": "conda-env-python27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
