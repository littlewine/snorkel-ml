{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "from snorkel.models import  Document, Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonis/anaconda2/envs/python27/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/antonis/anaconda2/envs/python27/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "from snorkel.lf_helpers import *\n",
    "import pickle,glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from MLutils import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MLutils import diversity_heatmap, merge_pickles_pred_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import Candidate, candidate_subclass\n",
    "REGULATOR = candidate_subclass('REGULATOR', ['Chemical', 'Gene'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure unmapped cands are gone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import  any_,or_,and_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 0 candidates from split=0 in to_drop list\n",
      "Adding 0 candidates from split=1 in to_drop list\n",
      "Adding 0 candidates from split=2 in to_drop list\n"
     ]
    }
   ],
   "source": [
    "#create list of unmapped cands to drop\n",
    "to_drop = []\n",
    "for k in range(3):\n",
    "    query = session.query(REGULATOR).filter(and_(REGULATOR.split==k,~REGULATOR.gold_labels.any()))\n",
    "    print 'Adding %i candidates from split=%i in to_drop list'%(query.count(), k)\n",
    "    to_drop.extend(map(lambda x: x.id,query.all()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #drop unmapped cands\n",
    "# query = session.query(Candidate).filter(Candidate.id.in_(to_drop))\n",
    "# print query.count()\n",
    "# query.delete(synchronize_session=False)\n",
    "# session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve results and pick models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict = merge_pickles_pred_dicts(glob.glob('ml_predictions/*.pkl'), \n",
    "#                                         f1_threshold=0.49,\n",
    "#                                         list_substr=['results_dict,','minFreq=3','_'],\n",
    "#                                         best_model=True,\n",
    "#                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ml_predictions/good_batch_Wed0606.pickle\", 'rb') as f:\n",
    "    results_dict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_unlab_binary',\n",
       " 'label_val_prob_dict',\n",
       " 'label_unlab_prob_dict',\n",
       " 'f1+',\n",
       " 'label_test_binary',\n",
       " 'label_test_prob_dict',\n",
       " 'classification_report',\n",
       " 'label_val_binary']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[model_name].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1,  1, ...,  1,  1, -1])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[model_name]['label_unlab_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.5 results_dict,RuS,TfIdf_,minFreq=1,_stopw=english,_ngrams=(0, 3)_LogisticRegression\n",
      "Keys matching:  True\n",
      "[0.5017025727036131, 0.47117860808650647, 0.47117860808650647, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5107918862337189]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "0.5 results_dict,trim=0,RuS,CV_,bin_,minFreq=3,_stopw=english,LSA100_RandomForestClassifier\n",
      "Keys matching:  True\n",
      "[0.5017025727036131, 0.47117860808650647, 0.47117860808650647, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5107918862337189]\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "0.53 results_dict,trim=5,RuS,CV_,bin_,minFreq=3,_stopw=english,LSA100_SVC_rbf_C=500\n",
      "Keys matching:  True\n",
      "[0.5017025727036131, 0.47117860808650647, 0.47117860808650647, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5107918862337189]\n",
      "[1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "0.49568965517241376 RuS,lr=0.001,dropout=0.25,15epochs,rebalance=0.25,max_sent_length=64_biLSTM\n",
      "Keys matching:  True\n",
      "[0.5017025727036131, 0.47117860808650647, 0.47117860808650647, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5107918862337189]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "0.5 results_dict,RuS,CV_,bin_,minFreq=3,_stopw=english_RandomForestClassifier\n",
      "Keys matching:  True\n",
      "[0.5017025727036131, 0.47117860808650647, 0.47117860808650647, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5056995267978837, 0.5107918862337189]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "unlab_keys0 = set(results_dict[results_dict.keys()[0]]['label_unlab_prob_dict'].keys())\n",
    "#check model performance\n",
    "for model_name in results_dict.keys():\n",
    "    print '\\n',results_dict[model_name]['f1+'], model_name\n",
    "    print 'Keys matching: ',unlab_keys0 == set(results_dict[model_name]['label_unlab_prob_dict'].keys())\n",
    "    result_prob = [results_dict[model_name]['label_unlab_prob_dict'][cid] for cid in sorted(results_dict[model_name]['label_unlab_prob_dict'].keys(), reverse=True)]\n",
    "    result_bin = [0 if prob<=0.5 else 1 for prob in result_prob]\n",
    "    print result[:10]\n",
    "    print result_bin[-1110:-1000]\n",
    "    \n",
    "    \n",
    "    print result_unlab_binary01[-1110:-1000]\n",
    "    \n",
    "#     print result_bin == result_unlab_binary01\n",
    "    \n",
    "    \n",
    "    # deal with this shit later.... nice confidence there man!\n",
    "#     pd.Series(result).hist()\n",
    "#     plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [results_dict[key] for model_name in sorted(results_dict.keys(), reverse=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** heuristic developed for model selection **\n",
    "\n",
    "(replaced by classifier selection.ipynb )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = sorted(results_dict.keys())\n",
    "cohens_df = pd.DataFrame(index=model_names, columns=model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_on= 'label_val_binary'\n",
    "for i,model1 in enumerate(cohens_df.index):\n",
    "    for j,model2 in enumerate(cohens_df.columns):\n",
    "        if i==j:\n",
    "            cohens_df.iloc[i,j] = 0\n",
    "        else:\n",
    "            cohens_df.iloc[i,j] = cohen_kappa_score(results_dict[model1][evaluate_on],results_dict[model2][evaluate_on])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RuS,lr=0.001,dropout=0.25,15epochs,rebalance=0.25,maxsentlength=64_biLSTM'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cohens_df.mean().sort_values().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_models = ['trim=5,RuS,CV,bin,,stopw=english,LSA100_SVC_rbf_C=500',\n",
    "#                   'lemmas,RuS,TfIdf,,stopw=english_SVC_rbf_C=500'\n",
    "                  \n",
    "#                   ]\n",
    "# candidate_model = ['trim=5,lemmas,RuS,TfIdf,,stopw=english_LogisticRegression',]\n",
    "\n",
    "\n",
    "# max([cohens_df.ix[candidate_model, selected_model].values[0] for selected_model in selected_models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def select_models(cohens_df, diversity_threshold , f1_threshold=0):\n",
    "#     selected_models = [cohens_df.mean().sort_values().index[0]]\n",
    "#     for candidate_model in cohens_df.mean().sort_values().index[1:]:\n",
    "#         #check whether all cohens kappas are < threshold\n",
    "#         if max([cohens_df.ix[candidate_model, selected_model] for selected_model in selected_models])<diversity_threshold:\n",
    "#             selected_models.append(candidate_model)\n",
    "#     return selected_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RuS,lr=0.001,dropout=0.25,15epochs,rebalance=0.25,maxsentlength=64_biLSTM',\n",
       " 'trim=0,RuS,CV,bin,,stopw=english,LSA100_RandomForestClassifier']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selected_models = select_models(cohens_df, diversity_threshold = 0.2, )\n",
    "\n",
    "# selected_models\n",
    "# # results_dict1 = {}\n",
    "# # for key in selected_models:\n",
    "# #     results_dict1[key]=results_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-620c62e1eaa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiversity_heatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_models\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccuracy_score\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "diversity_heatmap(results_dict[[selected_models]], figsize=(20,20), metric=accuracy_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trim=5,RuS,CV,bin,,stopw=english,LSA100_SVC_rbf_C=500 0.4850880814909812\n"
     ]
    }
   ],
   "source": [
    "lowest_model_name = cohens_df.mean().idxmin()\n",
    "print cohens_df.mean().idxmin() , cohens_df.mean().min()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the generative model (denoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** with label generator **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_annotator(c):\n",
    "    \"\"\"A generator over the different (worker_id, label_id) pairs for a Tweet.\"\"\"\n",
    "    for model in results_dict1.keys():\n",
    "\n",
    "        #hack to convert labels to -1,1....\n",
    "        #TODO: switch back to unlab again\n",
    "        yield model, (results_dict1[model]['label_test_prob_dict'][c.id] > 0.5)*2-1\n",
    "#         yield model, (results_dict[model]['label_unlab_prob_dict'][c.id] > threshold)*2-1\n",
    "\n",
    "#         try:\n",
    "#             yield model, results_dict[model]['label_unlab_prob_dict'][c.id]\n",
    "#         except:\n",
    "#             yield model, 0\n",
    "\n",
    "labeler = LabelAnnotator(label_generator=signal_annotator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** with LFs **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_exist_for(c):\n",
    "    \"\"\"For now, skip unmapped candidates in the test set - as no predictions where generated for them.\"\"\"\n",
    "    if c.id in results_dict[results_dict.keys()[0]]['label_unlab_prob_dict'].keys():\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cand = session.query(REGULATOR).filter(REGULATOR.split==3).all()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_exist_for(random_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict['lemmas,RuS,TfIdf,,stopw=english,LSA100_SVC_rbf_C=500'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diversity_heatmap(results_dict, figsize=(20,20), metric=accuracy_score )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohens_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['results_dict,RuS,TfIdf_,minFreq=1,_stopw=english,_ngrams=(0, 3)_LogisticRegression',\n",
       " 'results_dict,trim=0,RuS,CV_,bin_,minFreq=3,_stopw=english,LSA100_RandomForestClassifier',\n",
       " 'results_dict,trim=5,RuS,CV_,bin_,minFreq=3,_stopw=english,LSA100_SVC_rbf_C=500',\n",
       " 'RuS,lr=0.001,dropout=0.25,15epochs,rebalance=0.25,max_sent_length=64_biLSTM',\n",
       " 'results_dict,RuS,CV_,bin_,minFreq=3,_stopw=english_RandomForestClassifier']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "['RuS,lr=0.001,dropout=0.25,15epochs,rebalance=0.25,maxsentlength=64_biLSTM',\n",
    " 'trim=0,RuS,CV,bin,,stopw=english,LSA100_RandomForestClassifier',\n",
    "'RuS,CV,bin,,stopw=english_RandomForestClassifier',\n",
    "]\n",
    "\n",
    "def biLSTM(c):\n",
    "    if predictions_exist_for(c):\n",
    "        return -1 if results_dict['RuS,lr=0.001,dropout=0.25,15epochs,rebalance=0.25,max_sent_length=64_biLSTM']['label_unlab_prob_dict'][c.id]>=0.5 else 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def BOW_TFidf_upto_3grams(c):\n",
    "    if predictions_exist_for(c):\n",
    "        return -1 if results_dict['results_dict,RuS,TfIdf_,minFreq=1,_stopw=english,_ngrams=(0, 3)_LogisticRegression']['label_unlab_prob_dict'][c.id]>=0.5 else 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def BOW_CV_trimwindow0_LSA100_RF(c):\n",
    "    if predictions_exist_for(c):\n",
    "        return -1 if results_dict['results_dict,trim=0,RuS,CV_,bin_,minFreq=3,_stopw=english,LSA100_RandomForestClassifier']['label_unlab_prob_dict'][c.id]>=0.5 else 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def BOW_CV_trimwindow5_LSA100_SVCgaussian(c):\n",
    "    if predictions_exist_for(c):\n",
    "        return -1 if results_dict['results_dict,trim=5,RuS,CV_,bin_,minFreq=3,_stopw=english,LSA100_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>=0.5 else 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def BOW_CV_RF(c):\n",
    "    if predictions_exist_for(c):\n",
    "        return -1 if results_dict['results_dict,RuS,CV_,bin_,minFreq=3,_stopw=english_RandomForestClassifier']['label_unlab_prob_dict'][c.id]>=0.5 else 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pass classifier output as signals\n",
    "\n",
    "\n",
    "# def mod1(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict['trim=0,lemmas,RuS,CV,bin,,stopw=english,LSA100_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        \n",
    "# def mod2(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict['trim=5,RuS,CV,bin,,stopw=english_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        \n",
    "# def mod3(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict['trim=5,RuS,CV,bin,,stopw=english,LSA100_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        \n",
    "# def mod4(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict['RuS,TfIdf,,stopw=english_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # unlab\n",
    "\n",
    "# # Pass classifier output as signals\n",
    "\n",
    "\n",
    "# def mod1(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict1['trim=0,lemmas,RuS,CV,bin,,stopw=english,LSA100_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        \n",
    "# def mod2(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict1['trim=5,RuS,CV,bin,,stopw=english_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        \n",
    "# def mod3(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict1['trim=5,RuS,CV,bin,,stopw=english,LSA100_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        \n",
    "# def mod4(c):\n",
    "#     if predictions_exist_for(c):\n",
    "#         return -1 if results_dict1['RuS,TfIdf,,stopw=english_SVC_rbf_C=500']['label_unlab_prob_dict'][c.id]>0.5 else 1\n",
    "#     else:\n",
    "#         return 0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LFs = [mod1,mod2,mod3,mod4]\n",
    "LFs = [biLSTM,BOW_TFidf_upto_3grams,BOW_CV_trimwindow0_LSA100_RF,BOW_CV_trimwindow5_LSA100_SVCgaussian,BOW_CV_RF]\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 9min 59s, sys: 148 ms, total: 9min 59s\n",
      "Wall time: 9min 59s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<79460x5 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 397300 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time L_train = labeler.apply(split=3)\n",
    "L_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biLSTM</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_TFidf_upto_3grams</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_CV_trimwindow0_LSA100_RF</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_CV_trimwindow5_LSA100_SVCgaussian</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_CV_RF</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       j  Coverage  Overlaps  Conflicts\n",
       "biLSTM                                 0       1.0       1.0   0.942046\n",
       "BOW_TFidf_upto_3grams                  1       1.0       1.0   0.942046\n",
       "BOW_CV_trimwindow0_LSA100_RF           2       1.0       1.0   0.942046\n",
       "BOW_CV_trimwindow5_LSA100_SVCgaussian  3       1.0       1.0   0.942046\n",
       "BOW_CV_RF                              4       1.0       1.0   0.942046"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see how many LF vote on how many examples & with how many other LFs there are votes on common examples\n",
    "L_train.lf_stats(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find dependencies between LFs\n",
    "\n",
    "from snorkel.learning.structure import DependencySelector\n",
    "ds = DependencySelector()\n",
    "deps = ds.select(L_train, threshold=0.07)\n",
    "len(deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred cardinality: 2\n"
     ]
    }
   ],
   "source": [
    "# actual training of the gen. model\n",
    "from snorkel.learning import GenerativeModel\n",
    "\n",
    "gen_model = GenerativeModel(lf_propensity=True)\n",
    "gen_model.train(\n",
    "    L_train, decay=0.95, step_size=0.1/L_train.shape[0], reg_param=0.0, deps=deps, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_marginals = gen_model.marginals(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plt.hist(train_marginals, bins=20)\n",
    "# sns.distplot(train_marginals,bins=20)\n",
    "# plt.title('Histogram of probabilistic labels (good_batch.pickle)')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(train_marginals, bins=20)\n",
    "plt.title('Histogram of probabilistic labels (1x BOW + 1x biLSTM)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<snorkel.learning.gen_learning.GenerativeModelWeights at 0x7f879d95ba90>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But it still thinks its smart!!!! \n",
      "LOOK:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.250878</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>0.250384</td>\n",
       "      <td>0.197613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.941265</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>0.943715</td>\n",
       "      <td>0.813916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.914663</td>\n",
       "      <td>0.8484</td>\n",
       "      <td>0.912929</td>\n",
       "      <td>0.774070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951805</td>\n",
       "      <td>0.8839</td>\n",
       "      <td>0.948712</td>\n",
       "      <td>0.841828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.890447</td>\n",
       "      <td>0.8416</td>\n",
       "      <td>0.890089</td>\n",
       "      <td>0.750202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Coverage  Precision    Recall\n",
       "0  0.250878    0.7685   0.250384  0.197613\n",
       "1  0.941265    0.8683   0.943715  0.813916\n",
       "2  0.914663    0.8484   0.912929  0.774070\n",
       "3  0.951805    0.8839   0.948712  0.841828\n",
       "4  0.890447    0.8416   0.890089  0.750202"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print 'But it still thinks its smart!!!! \\nLOOK:'\n",
    "gen_model.learned_lf_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check performance on developer set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3237x1 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 3237 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from db gold labels\n",
    "L_gold_dev = load_gold_labels(session, annotator_name='gold', split=1)\n",
    "L_gold_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_dev = labeler.apply_existing(split=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3237x5 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonis/snorkel/snorkel/annotations.py:137: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ac = (tp+tn) / (tp+tn+fp+fn)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biLSTM</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.247011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_TFidf_upto_3grams</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.939844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_CV_trimwindow0_LSA100_RF</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_CV_trimwindow5_LSA100_SVCgaussian</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOW_CV_RF</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.886893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       j  Coverage  Overlaps  Conflicts  TP  \\\n",
       "biLSTM                                 0       0.0       0.0        0.0   0   \n",
       "BOW_TFidf_upto_3grams                  1       0.0       0.0        0.0   0   \n",
       "BOW_CV_trimwindow0_LSA100_RF           2       0.0       0.0        0.0   0   \n",
       "BOW_CV_trimwindow5_LSA100_SVCgaussian  3       0.0       0.0        0.0   0   \n",
       "BOW_CV_RF                              4       0.0       0.0        0.0   0   \n",
       "\n",
       "                                       FP  FN  TN  Empirical Acc.  \\\n",
       "biLSTM                                  0   0   0             NaN   \n",
       "BOW_TFidf_upto_3grams                   0   0   0             NaN   \n",
       "BOW_CV_trimwindow0_LSA100_RF            0   0   0             NaN   \n",
       "BOW_CV_trimwindow5_LSA100_SVCgaussian   0   0   0             NaN   \n",
       "BOW_CV_RF                               0   0   0             NaN   \n",
       "\n",
       "                                       Learned Acc.  \n",
       "biLSTM                                     0.247011  \n",
       "BOW_TFidf_upto_3grams                      0.939844  \n",
       "BOW_CV_trimwindow0_LSA100_RF               0.913698  \n",
       "BOW_CV_trimwindow5_LSA100_SVCgaussian      0.945980  \n",
       "BOW_CV_RF                                  0.886893  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_dev.lf_stats(session, L_gold_dev, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yes, because my LFs vote only on the unlabeled set results!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save probabilistic labels for the LSTM  -  this is the # of train. examples our LSTM will train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 79460 marginals\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import save_marginals\n",
    "save_marginals(session, L_train, train_marginals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_unlab_binary',\n",
       " 'label_val_prob_dict',\n",
       " 'label_unlab_prob_dict',\n",
       " 'f1+',\n",
       " 'label_val_binary',\n",
       " 'label_test_prob_dict',\n",
       " 'classification_report',\n",
       " 'label_test_binary']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict1['trim=5,RuS,CV,bin,,stopw=english_SVC_rbf_C=500']['label_unlab_binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6599743510370141\n",
      "0.7940850742511956\n",
      "0.5008445741717802\n"
     ]
    }
   ],
   "source": [
    "mod1pred = results_dict1['trim=5,RuS,CV,bin,,stopw=english_SVC_rbf_C=500']['label_unlab_binary']\n",
    "mod2pred = results_dict1['trim=5,RuS,CV,bin,,stopw=english,LSA100_SVC_rbf_C=500']['label_unlab_binary']\n",
    "print precision_score(mod1pred,mod2pred)\n",
    "print accuracy_score(mod1pred,mod2pred)\n",
    "print cohen_kappa_score(mod1pred,mod2pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n",
      "[========================================] 100%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "L_test = labeler.apply_existing(split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<13350x1 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 5781 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load from db gold labels\n",
    "L_gold_test = load_gold_labels(session, annotator_name='gold', split=2)\n",
    "L_gold_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scores (Un-adjusted)\n",
      "========================================\n",
      "Pos. class accuracy: 0.259\n",
      "Neg. class accuracy: 0.975\n",
      "Precision            0.57\n",
      "Recall               0.259\n",
      "F1                   0.356\n",
      "----------------------------------------\n",
      "TP: 388 | FP: 293 | TN: 11557 | FN: 1112\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = gen_model.error_analysis(session, L_test, L_gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>TN</th>\n",
       "      <th>Empirical Acc.</th>\n",
       "      <th>Learned Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dummy</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.128764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1500</td>\n",
       "      <td>4281</td>\n",
       "      <td>0.740529</td>\n",
       "      <td>0.936173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>1</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.128764</td>\n",
       "      <td>683</td>\n",
       "      <td>563</td>\n",
       "      <td>817</td>\n",
       "      <td>3718</td>\n",
       "      <td>0.761287</td>\n",
       "      <td>0.893057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_linear</th>\n",
       "      <td>2</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.128764</td>\n",
       "      <td>594</td>\n",
       "      <td>592</td>\n",
       "      <td>906</td>\n",
       "      <td>3689</td>\n",
       "      <td>0.740875</td>\n",
       "      <td>0.888321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_rbf_C100</th>\n",
       "      <td>3</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.128764</td>\n",
       "      <td>606</td>\n",
       "      <td>500</td>\n",
       "      <td>894</td>\n",
       "      <td>3781</td>\n",
       "      <td>0.758865</td>\n",
       "      <td>0.893826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_rbf_C500</th>\n",
       "      <td>4</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.128764</td>\n",
       "      <td>625</td>\n",
       "      <td>484</td>\n",
       "      <td>875</td>\n",
       "      <td>3797</td>\n",
       "      <td>0.764920</td>\n",
       "      <td>0.897841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC_rbf_C1000</th>\n",
       "      <td>5</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.433034</td>\n",
       "      <td>0.128764</td>\n",
       "      <td>577</td>\n",
       "      <td>480</td>\n",
       "      <td>923</td>\n",
       "      <td>3801</td>\n",
       "      <td>0.757308</td>\n",
       "      <td>0.899282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    j  Coverage  Overlaps  Conflicts   TP   FP    FN    TN  \\\n",
       "dummy               0  1.000000  0.433034   0.128764    0    0  1500  4281   \n",
       "LogisticRegression  1  0.433034  0.433034   0.128764  683  563   817  3718   \n",
       "SVC_linear          2  0.433034  0.433034   0.128764  594  592   906  3689   \n",
       "SVC_rbf_C100        3  0.433034  0.433034   0.128764  606  500   894  3781   \n",
       "SVC_rbf_C500        4  0.433034  0.433034   0.128764  625  484   875  3797   \n",
       "SVC_rbf_C1000       5  0.433034  0.433034   0.128764  577  480   923  3801   \n",
       "\n",
       "                    Empirical Acc.  Learned Acc.  \n",
       "dummy                     0.740529      0.936173  \n",
       "LogisticRegression        0.761287      0.893057  \n",
       "SVC_linear                0.740875      0.888321  \n",
       "SVC_rbf_C100              0.758865      0.893826  \n",
       "SVC_rbf_C500              0.764920      0.897841  \n",
       "SVC_rbf_C1000             0.757308      0.899282  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L_test.lf_stats(session, L_gold_test, gen_model.learned_lf_stats()['Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python27]",
   "language": "python",
   "name": "conda-env-python27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
