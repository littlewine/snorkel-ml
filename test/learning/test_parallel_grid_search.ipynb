{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Parallel `GridSearch`\n",
    "\n",
    "Note: Currently there are issues with running in a notebook where other models are run (see [Issue #707](https://github.com/HazyResearch/snorkel/issues/707)), so running here in separate notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "os.environ['SNORKELDB'] = 'sqlite:///{0}{1}crowdsourcing.db'.format(os.getcwd(), os.sep)\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load candidates and training marginals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "from snorkel.contrib.models.text import RawText\n",
    "Tweet = candidate_subclass('Tweet', ['tweet'], cardinality=5)\n",
    "train_tweets = session.query(Tweet).filter(Tweet.split == 0).order_by(Tweet.id).all()\n",
    "len(train_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import load_marginals\n",
    "train_marginals = load_marginals(session, train_tweets, split=0)\n",
    "train_marginals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_labels = np.load('crowdsourcing_test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.learning.utils import GridSearch\n",
    "from snorkel.learning import TextRNN\n",
    "\n",
    "test_tweets = session.query(Tweet).filter(Tweet.split == 1).order_by(Tweet.id).all()\n",
    "\n",
    "# Searching over learning rate and embedding dimension\n",
    "param_ranges = {'lr': [1e-3, 1e-4], 'dim': [50, 100]}\n",
    "model_class_params = {'seed' : 123, 'cardinality': Tweet.cardinality, 'n_threads': 2}\n",
    "model_hyperparams = {\n",
    "    'dim':        50,\n",
    "    'n_epochs':   20,\n",
    "    'dropout':    0.2,\n",
    "    'print_freq': 10\n",
    "}\n",
    "searcher = GridSearch(TextRNN, param_ranges, train_tweets, train_marginals,\n",
    "    model_class_params=model_class_params, model_hyperparams=model_hyperparams)\n",
    "\n",
    "# Use test set here (just for testing)\n",
    "lstm, run_stats = searcher.fit(test_tweets, test_labels, n_threads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = lstm.score(test_tweets, test_labels)\n",
    "print(acc)\n",
    "assert acc > 0.60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
